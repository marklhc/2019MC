---
title: "Advancing Quantitative Science"
subtitle: "with Monte Carlo Simulation <html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
author: "Hok Chio (Mark) Lai"
date: "2021/06/16"
output:
  xaringan::moon_reader:
    css: [default, my-theme.css]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{css echo = FALSE}
.remark-slide-number {
  opacity: 0; /* default: 0.5 */
}
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
theme_set(theme_bw())
```

```{r load-RefManageR, load_refs, echo = FALSE, cache = FALSE, message = FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE, 
           max.names = 1, 
           no.print.fields = c("url", "issn", "language", "urldate"),
           longnamesfirst = FALSE)
myBib <- ReadBib("./references.bib", check = FALSE)
```

# Overview

### What is Monte Carlo (MC) simulation?

--

### Simulating Data From a Normal Distribution

--

### Properties of Estimators

--

### Monte Carlo Simulation Study/Experiment

---

# Monte Carlo Methods

.pull-left[

- 1930s-1940s: Nuclear physics

   * Key figures:
   
       * Stanislaw Ulam
       * John von Neumann
       * Nicholas Metropolis
   
   * Manhattan project: hydrogen bomb

- Naming: Casino in Monaco

]

.pull-right[
![](https://upload.wikimedia.org/wikipedia/commons/3/36/Real_Monte_Carlo_Casino.jpg)
]

.footnote[

Image credit: sam garza from Los Angeles, USA, CC BY 2.0 <https://creativecommons.org/licenses/by/2.0>, via Wikimedia Commons

]

---

# Why Do We Do Statistics?

- To study some target quantity in the population

    * Based on a limited sample

- How do we know that a statistics/statistical method gets us to a reasonable answer?

    * Analytic method

    * Simulation

---
class: inverse, center, middle

# MC is one way to understand the properties of one or more statistical procedures

---

# What is MC (in Statistics)?

### A statistical technique that uses (psuedo-random) sampling to get numerical results

--

- Simulate the _process of repeated random sampling_

    * E.g., repeatedly drawing sample of IQ scores of size 10 from a population
    
- Approximate _sampling distributions_
    
    * Using **pseudorandom samples**
    
- Study properties of **statistical methods**

    * regression coefficients, fit index

    * compare multiple estimators or modeling approaches

---
exclude: true

# What is it (cont'd)?

- Based on Carsey & Harden (2014):

    * Simulations as experiments

        * Whether there's a "treatment" effect (but not why)

    * Simulations help develop intuition

        * Shouldn't replace analytically and theoretical reasoning 

    * Simulations help evaluate substantive theories and empirical results

???

Sometimes analytic solution does not exist

---
class: inverse, middle, center

# Simulating Random Data From a Normal Distribution

---

# Generating Random Data in R

With MC, one simulates the process of generating the data with an assumed 
**data generating model/mechanism**

<!-- - Model: including both functional form and distributional assumptions -->

```{r rnorm}
rnorm(5, mean = 0, sd = 1)
rnorm(5, mean = 0, sd = 1)  # numbers changed
```

---

# Setting the Seed

- Most programs use algorithms to generate numbers that look like random, i.e., _pseudorandom_

    * Completely determined by the **state** of the random number generator, which can be set by the seed

- For replicability, set the seed explicitly

---

```{r seed}
state1 <- .Random.seed  # state of RNG
rnorm(5, mean = 0, sd = 1)
set.seed(1)
state2 <- .Random.seed  # state of RNG changed
identical(state1, state2)
rnorm(5, mean = 0, sd = 1)
set.seed(1)
state3 <- .Random.seed  # state of RNG unchanged with the same seed
identical(state2, state3)
rnorm(5, mean = 0, sd = 1)  # same seed, same numbers
```

---

# Generating Data From Univariate Distributions

```{r, eval=FALSE}
rnorm(n, mean, sd)      # Normal distribution (mean and SD)
runif(n, min, max)      # Uniform distribution (minimum and maximum)
rchisq(n, df)           # Chi-squared distribution (degrees of freedom)
rbinom(n, size, prob)   # Binomial distribution
```

???

Other distributions include `exponential`, `gamma`, `beta`, `t`, `F`

---

# MC Approximation of $N(0, 1)$

```{r norm-approx-20, message = FALSE, fig.width = 4, fig.height = 3.5, fig.align = "center"}
library(tibble)
library(ggplot2)
set.seed(123)
nsim <- 20  # 20 samples
sam <- rnorm(nsim)  # default is mean = 0 and sd = 1
ggplot(tibble(x = sam), aes(x = x)) + 
  geom_density(bw = "SJ") + 
  stat_function(fun = dnorm, col = "red")  # overlay normal curve in red
```

---
class: inverse, middle, center

# Exercise

### Try increasing `nsim` to 100, then 1,000

---

# Exercise 

```{r animate-sim-norm, results = "hide", echo = FALSE, animation.hook = "ffmpeg", ffmpeg.format = "gif", interval = 0.2, dev = "jpeg", message = FALSE, fig.width = 4.5, fig.asp = 1, fig.retina = 2, fig.align = "center", out.width = "60%"}
set.seed(123)
nsim <- 1000  # 20 samples
sam <- rnorm(nsim)  # default is mean = 0 and sd = 1
plist <- vector("list", nsim / 10)
for (i in seq_along(plist)) {
  sam_t <- sam[1:(i * 10)]
  plist[[i]] <- ggplot(tibble(x = sam_t), aes(x = x)) +
    geom_histogram(aes(y = ..density..)) +
    stat_function(fun = dnorm, col = "red") +  # overlay normal curve in red
    annotate("text", label = paste("italic(n) == ", i * 10), 
             parse = TRUE, x = Inf, y = Inf, vjust = 1, hjust = 1)
}
plist
```

---
class: inverse, middle, center

# Evaluating Properties of Statistical Methods

---

# Some Types of Methods Studied by Simulations

Adapted from Table 3 of `r Citet(myBib, "Morris2019")`

```{r tab-common-target, echo = FALSE}
knitr::kable(
  tibble(
    Task = c("Estimation", "Uncertainty", "Inference", "Model Selection"),
    `Statistical Method` = c("Estimator", "Standard error, confidence interval", 
                             "Hypothesis testing", "Model selection index"),
    Properties = c("Bias, efficiency, consistency",
                   "SE bias, coverage",
                   "Type I error rate, power",
                   "Correct model rate")
  )
)
```

--

One additional property: **Robustness**---resilience against outliers and assumption violations

---

# Estimation: Parameter vs Estimator

- **Estimator**/statistic: $T(\mathbf{X})$, or simply $T$

    * How good does it estimate the population parameter, $\theta$?
    
- Examples:
    
    * $T = \bar{X}$ estimates $\theta = \mu$
    
    * $T = \dfrac{\sum_i (X_i - \bar{X})^2}{N - 1}$ estimates $\theta = \sigma^2$

---
exclude: true

# Some Properties of Estimators

- Unbiasedness

- Consistency

- Efficiency

- Robustness

---

# What is a Good Estimator?

```{r, echo = FALSE, out.width = '75%', fig.align = 'center'}
knitr::include_graphics("images/bias&efficiency.png")
```

---

# Sampling Distribution

- What is it?

```{r samp-dist-chisq, echo = FALSE, message = FALSE, fig.width = 4.5, fig.asp = 1, fig.align = "center", out.width = "60%"}
NREP <- 1e4  # number of replications
sample_size <- 10  # define sample size
# Initialize place holders for results
sam_means <- rep(NA, NREP)  # an empty vector with NREP elements
for (i in seq_len(NREP)) {
  sam_means[i] <- mean(rchisq(sample_size, df = 4))
}
ggplot(data = tibble(xbar = sam_means), 
       aes(x = xbar)) + 
  geom_histogram() + 
  labs(x = expression(bar(italic(X))))
```


---
class: inverse, center, middle

# Example I

### Simulating Means and Medians

---
exclude: true

# When to use MC?

- To understand statistical models concepts

    * E.g., Mixed model, Type I error, Power

- When it's difficult to analytically derive the sampling distribution
    
    * E.g., indirect effect, fit-indexes; Cohen's $d$, *SE*s of estimators
    
- When required assumptions are violated
    
    * E.g., normality, large sample
    * Model is misspecified
    * Used to check **robustness** of the estimator

---
class: inverse, center, middle

# Monte Carlo Simulation Study

---

# Examples in the Literature

- [Curran, West, & Finch (1996, Psych Methods)](doi.org/10.1037/1082-989X.1.1.16) studied the performance of the $\chi^2$ test for nonnormal data in CFA

- [Kim & Millsap (2014, MBR)](doi.org/10.1080/00273171.2014.947352) studied the performance of the Bollen-Stine Bootstrapping method for evaluating SEM fit indices

- [MacCallum, Widaman, Zhang, & Hong (1999, Psych Methods)](doi.org/10.1037/1082-989X.4.1.84) studied sample size requirement for getting stable EFA results
- [Maas & Hox (2005, Methodology)](http://dx.doi.org/10.1027/1614-2241.1.3.86) studied the sample size requirement for multilevel models

---

# A Simulation Study is an Experiment

Experiment | Simulation
-----------|------------
Independent variables | Design factors 
Experimental conditions | Simulation conditions
Controlled variables | Other parameters
Procedure/Manipulation | Data generating model
Dependent variables | Evaluation measures
Substantive theory | Statistical theory
Participants | Replications

---
exclude: true

class: clear, center

```{r, echo=FALSE, out.width='65%'}
knitr::include_graphics("images/Sigal&Chalmers_figure1.png")
```

`r Citep(myBib, "Sigal2016", after = ", Figure 1, p. 141")`

---

# Framework

`r Citep(myBib, c("Sigal2016", "Chalmers2020", "Morris2019"))`

- Research questions
    * *What is the effect of ignoring random slopes in a growth model?*
    
- Design
    * *3 (N = 50, 100, 200) $\times$ 2 (slope variance = 0.1, 0.5) design*
    * *Constant: 4 time points, maximum likelihood estimation, etc*
    * *500 replications*
    
- Date-generating model (fixed and random components)
    * *linear growth model with normally distributed errors*

---

# Framework (cont'd)

- Statistical methods
    1. *slope estimate and standard error under correctly specified latent growth model with lavaan*
    2. *slope estimate and standard error under misspecified model*

- Evaluative measures
    * *convergence, bias, SE bias, relative efficiency*
    
- Summary and reporting
    * *Table, plot*

---

# Design

Like experimental designs, conditions should be carefully chosen
- What to manipulate? Sample size? Effect size? Why?
    * Based on statistical theory and reasoning
    * E.g., Gauss-Markov theorem: regression coefficients are unbiased with 
    violations of distributional assumptions

--

- What levels? Why?
    * Needs to be realistic for empirical research
    * Maybe based on previous systematic reviews, 
    * Or a small review of your own

--

Full Factorial designs are most commonly used

- Fractional factorial may sometimes be beneficial `r Citep(myBib, "skrondal2000")`

---

# Data Generation

- Starts with a statistical data generating model
    * E.g., $Y_i = \beta_0 + \beta_1 X_i + e_i,\quad e_i \overset{\textrm{i.i.d.}}{\sim} N(0, \sigma^2)$
        + Systematic (deterministic) component: $X_i$
        + Random (stochastic) component: $e_i$
        + Constants (parameters): $\beta_0$, $\beta_1$
    * $Y_i$ completely determined by $X_i, e_i, \beta_0, \beta_1$
    
```{r, echo=FALSE, fig.height=3.5}
DiagrammeR::grViz("
digraph reg {

  # a 'graph' statement
  graph [overlap = true, fontsize = 10]

  # several 'node' statements
  node [shape = box,
        fontname = Helvetica]
  X; Y

  node [shape = circle,
        fixedsize = true] // sets as circles
  e

  # several 'edge' statements
  X -> Y
  e -> Y
  {rank = same; X; Y;}
}
")
```


---

# Model-Based Simulation

```{r, echo = FALSE, out.width = '75%', fig.align = 'center'}
knitr::include_graphics("images/sampdist2.png")
```

---
exclude: true

# Analyze

Analyze the simulated data using one or more analytic approaches
- Misspecification: study the impact when analytic model omits important aspects of data generating model
    * E.g., ignoring clustering
- Comparison of approaches
    * E.g., Maximum likelihood vs. multiple imputation for missing data handling

---

# Statistical Methods

- Analyze each simulated data set with one or more approaches/models

- Obtain statistics of interest (e.g., estimate, SE, CI, $p$ value)

---

# Evaluative Measures

.pull-left[

- Mean estimate $\bar{\hat \theta} = \sum_{i = 1}^R \hat \theta_i / R$
- Average estimated SE $\bar{\hat{\mathrm{SE}}}(\hat \theta) = \sum_{i = 1}^R \hat{\mathrm{SE}}(\hat \theta_i) / R$
- Empirical SE $\hat{\mathit{SD}}(\hat \theta)$ = 
  $\sqrt{\frac{\sum_{i = 1}^R (\theta_i - \bar{\hat \theta})^2}{R}}$

]

--

.pull-right[

Some measure for evaluating estimators:

- Bias
    * Raw: $\bar{\hat \theta} - \theta$
    * Relative: Bias / $\theta$
    * Standardized: Bias / $\hat{\mathit{SD}}(\hat \theta)$
- Relative efficiency (for unbiased estimators)
    * $\mathrm{RE}(\hat \theta, \tilde \theta)$ = $\frac{\hat{\mathrm{SE}}^2(\tilde \theta)}{\hat{\mathrm{SE}}^2(\hat \theta)}$
- Mean squared error (MSE)
    * $\mathrm{Bias}^2 + \hat{\mathrm{Var}}(\hat \theta)$
    * RMSE = $\sqrt{\mathrm{MSE}}$
    
]

---

# Evaluation Criteria (cont'd)

For uncertainty

- SE bias
    * Raw: $\bar{\mathit{SE}}(\hat \theta) - \hat{\mathit{SD}}(\hat \theta)$
    * Relative: SE bias / $\hat{\mathit{SD}}(\hat \theta)$
- Coverage
    * proportion of sample CI containing $\theta$

--

For statistical inferences:

- Power/Empirical Type I error rates
    * % with $p < \alpha$ (usually $\alpha$ = .05)
- Coverage of $C$% CI (e.g., $C$ = 95%)
    * % where the sample CI contains $\theta$

---
exclude: true
class: clear

.font80[
Criterion | Cutoff | Citation
-----|-------|----------
Bias |.|.
Relative bias | ≤5% | `r Citet(myBib, "hoogland1998")`
Standardized bias | ≤.40 | `r Citet(myBib, "collins2001")`
*SE* bias |.|.
Relative *SE* bias | ≤10% | `r Citet(myBib, "hoogland1998")`
MSE |.|.
RMSE |.|.
Empirical Type I error (α = .05) | 2.5% - 7.5% | `r Citet(myBib, "bradley1978")`
Power |.|.
95% CI Coverage | 91%-98% | `r Citet(myBib, "muthen2002")`
]

---

# Summary and Reporting

Same as analyzing real data

- Plots, figures

- ANOVA, regression
    * E.g., 3 (sample size) × 4 (parameter values) 2 (models) design: 2 between
    factors and 1 within factor

---
class: inverse, center, middle

# Example II

Simulation Example on Structural Equation Modeling

---
exclude: true

# Number of Replications

Should be justified rather than relying on rule of thumbs

## Why Does MC Work?

- Law of large number
    * $\sum_{i = 1}^R T_i / R \overset{p}{\to} \theta$
- When $R$ is large, 
    + the empirical distribution $\hat{F}(t)$ converges to the true sampling distribution $F(t)$. 

---
exclude: true

# Number of Replications (cont'd)

## How Good is the Approximation

- Monte Carlo (MC) Error 
    * Like standard error (SE) for a point estimate
- For expectations (e.g., bias)
    * MC Error = $\hat{\mathit{SD}}(\hat \theta) / \sqrt{R}$

E.g., if one wants the MC error to be ≤2.5% of the sampling variability, 
_R_ needs to be 1 / $.025^2$ = 1,600

---
exclude: true

# Number of Replications (cont'd)

For power (also Type I error) and CI coverage, 
* MC Error = $\sqrt{\frac{p (1 - p)}{R}}$

E.g., with _R_ = 250, and empirical Type I error = 5%, 
```{r}
sqrt((.05 * (1 - .05)) / 250)
```
So _R_ should be increase for more precise estimates

---
exclude: true

# Reporting MC Results

![](images/Boomsma_table1.png)

`r Citep(myBib, "boomsma2013", after = ", Table 1, p. 521")`

See `r Citet(myBib, "boomsma2013")`, Table 2, p. 526 for a checklist

---
exclude: true

# Efficiency tips

- Things that don't change should be outside of a loop
- Initialize place holders when using for-loops
- [Vectorize](https://adv-r.hadley.nz/perf-improve.html#vectorise)
- Strip out unnecessary computations
- Parallel computing (using the `future` package)

---
exclude: true

# Other topics not covered

- Error handling
- Assessing convergence
- Debugging
- Interfacing with other software (e.g., Mplus, LISREL, HLM)

---

# Further Readings

`r Citet(myBib, c("carsey2014", "Morris2019"))` for a gentle introduction

`r Citet(myBib, "Chalmers2020")` and `r Citet(myBib, "Sigal2016")` for using the R
package `SimDesign`

`r Citet(myBib, "Harwell2018")` for a review of design and reporting practices

`r Citet(myBib, "skrondal2000")`, `r Citet(myBib, "serlin2000")`, and 
`r Citet(myBib, "bandalos2013")` for additional topics

---

class: inverse, center, middle

# Thanks!

---

# References

.font70[
```{r, 'refs', results='asis', echo=FALSE}
PrintBibliography(myBib, start = 1, end = 5)
```
]

---

# References (cont'd)

.font70[
```{r, 'refs2', results='asis', echo=FALSE}
PrintBibliography(myBib, start = 6, end = 9)
```
]

---

# References (cont'd)

.font70[
```{r, 'refs3', results='asis', echo=FALSE}
PrintBibliography(myBib, start = 10, end = 13)
```
]
